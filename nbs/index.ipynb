{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/miniconda3/envs/clean_bench/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import logging\n",
    "\n",
    "from hf_clean_benchmarks.core import *\n",
    "\n",
    "# Turn off logging for datasets\n",
    "logging.getLogger(\"datasets\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hf_clean_benchmarks\n",
    "\n",
    "> This repository contains code for cleaning your training data of benchmark data to help combat data snooping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository is heavily inspired by the [BigCode repository](https://github.com/bigcode-project/bigcode-analysis/tree/main/data_analysis/decontamination) and is mostly a refactoring of their code. Specifically, the main person who worked on this repository is [Chenghao Mou](https://github.com/ChenghaoMou) (Awesome work!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install hf_clean_benchmarks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the API\n",
    "First you need to specify which benchmarks you want to clean your data of. You can do this by creating dictionary with the benchmark name in huggingface's datasets repository as the key and the name of the column containing the benchmark data as the value. For example, if you want to clean your data of the `HumanEval` and `LAMBADA` benchmarks, you would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarks to clean\n",
    "benchmarks = [\n",
    "    {\n",
    "        \"name\": \"openai_humaneval\",\n",
    "        \"splits\": [\"test\"],\n",
    "        \"columns\": [\"prompt\", \"canonical_solution\", \"test\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"lambada\",\n",
    "        \"splits\": [\"test\"],\n",
    "        \"columns\": [\"text\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You then pass this dictionary to the `BenchmarkCleaner` class. This class will download the benchmarks and construct the suffix array for each benchmark. You can then use the `clean` method to clean a huggingface dataset. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking for false positives...: 100%|██████████| 8780/8780 [00:34<00:00, 251.05it/s]\n",
      "Checking for false positives...: 100%|██████████| 8805/8805 [07:34<00:00, 19.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/06/22 10:34:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Data Number                   : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>                                      <a href=\"file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py#210\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/06/22 10:34:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Data Number                   : \u001b[1;36m10000\u001b[0m                                      \u001b]8;id=675856;file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=474784;file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py#210\u001b\\\u001b[2m210\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Duplicate Number              : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4033</span>                                       <a href=\"file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py#211\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">211</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Duplicate Number              : \u001b[1;36m4033\u001b[0m                                       \u001b]8;id=403017;file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=565451;file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py#211\u001b\\\u001b[2m211\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Duplicate Rate                : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40.33</span>%                                     <a href=\"file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py#212\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Duplicate Rate                : \u001b[1;36m40.33\u001b[0m%                                     \u001b]8;id=188124;file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=765969;file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py#212\u001b\\\u001b[2m212\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Total Time                    : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">493.73</span> seconds                             <a href=\"file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py#213\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Total Time                    : \u001b[1;36m493.73\u001b[0m seconds                             \u001b]8;id=718283;file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=927916;file:///home/nathan/projects/other/hf_clean_benchmarks/hf_clean_benchmarks/core.py#213\u001b\\\u001b[2m213\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from hf_clean_benchmarks.core import BenchmarkCleaner\n",
    "\n",
    "cleaner = BenchmarkCleaner(benchmarks, threshold=0.1, num_perm=128)\n",
    "\n",
    "# load your dataset\n",
    "dataset = load_dataset(\"bigcode/the-stack-smol\", data_dir=\"data/python\", split=\"train\")\n",
    "\n",
    "# clean the dataset\n",
    "cleaned_dataset = cleaner.clean(dataset, column=\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'avg_line_length', 'max_line_length', 'alphanum_fraction', 'licenses', 'repository_name', 'path', 'size', 'lang', '__id__'],\n",
       "    num_rows: 5967\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the CLI\n",
    "First you need to specify which benchmarks you want to clean your data of. You can do this by creating a json file with the benchmark name in huggingface's datasets repository as the key and the name of the column containing the benchmark data as the value. For example, if you want to clean your data of the `HumanEval` and `LAMBADA` benchmarks, you would do the following:\n",
    "\n",
    "file: `benchmarks.json`\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"name\": \"openai_humaneval\",\n",
    "        \"splits\": [\"test\"],\n",
    "        \"columns\": [\"prompt\", \"canonical_solution\", \"test\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"lambada\",\n",
    "        \"splits\": [\"test\"],\n",
    "        \"columns\": [\"text\"],\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "You then pass this json file to the `clean_dataset` command. This command will download the benchmarks and construct the suffix array for each benchmark. You can then use the `clean` command to clean a huggingface dataset. For example:\n",
    "\n",
    "```sh\n",
    "clean_dataset \\\n",
    "    --dataset_name bigcode/the-stack-smol \\\n",
    "    --column_name content \\\n",
    "    --benchmark_configs_path benchmarks.json \\\n",
    "    --output_path /tmp/test.jsonl \\\n",
    "    --data_dir data/python \\\n",
    "    --dataset_split train \\\n",
    "    --save_json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('clean_bench')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
