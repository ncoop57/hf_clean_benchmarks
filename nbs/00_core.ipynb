{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datasets import Dataset, load_dataset, Features, Sequence, Value\n",
    "from datasketch import LeanMinHash, MinHash, MinHashLSH\n",
    "from rich.logging import RichHandler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "multiprocessing.set_start_method(\"fork\", force=True)\n",
    "logging.getLogger(\"datasets\").setLevel(logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(RichHandler(rich_tracebacks=True))\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "MINHASH_SEED = 42\n",
    "NON_ALPHA = re.compile(\"[^A-Za-z_0-9]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def hash_content(\n",
    "    idx: int, # index of the document\n",
    "    content: str, # content of the document\n",
    "    *,\n",
    "    num_perm: int # number of permutations\n",
    "    ): # The MinHash signature and the index of the record.\n",
    "    \"\"\"\n",
    "    Hash the content of a record using MinHash. This function should be\n",
    "    used with multiprocessing and it scales well with the number of cores.\n",
    "    \"\"\"\n",
    "    m = MinHash(num_perm=num_perm, seed=MINHASH_SEED)\n",
    "    m.update_batch([token.encode(\"utf-8\") for token in {t for t in NON_ALPHA.split(content) if t}])\n",
    "    return {\"__signature__\": m.hashvalues, \"__id__\": idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = hash_content(0, \"Hello world!\", num_perm=128)\n",
    "assert result[\"__id__\"] == 0\n",
    "assert result[\"__signature__\"].shape == (128,)\n",
    "assert result[\"__signature__\"].dtype == np.dtype('uint64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def query_content(\n",
    "    idx: int, # index of the document\n",
    "    signature: np.ndarray, # MinHash signature of the document\n",
    "    *,\n",
    "    index: MinHashLSH # The MinHashLSH index. It is shared across all processes when using multiprocessing with fork without copy.\n",
    "    ): # The query result.\n",
    "    \"\"\"\n",
    "    Query the MinHashLSH index for the record. This function can be used with multiprocessing\n",
    "    as long as the index is shared across processes.\n",
    "    Parameters.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"__neighbors__\": [\n",
    "            str(dup_idx)\n",
    "            for dup_idx in index.query(\n",
    "                LeanMinHash(seed=MINHASH_SEED, hashvalues=signature),\n",
    "            )\n",
    "        ],\n",
    "        \"__id__\": idx,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def jaccard_similarity(\n",
    "    s1: str, # The first string to compare.\n",
    "    s2: str # The second string to compare.\n",
    "    ) -> float: # The Jaccard similarity between the two strings.\n",
    "    \"\"\"\n",
    "    Calculate the jaccard similarity between two code snippets.\n",
    "    \"\"\"\n",
    "    tokens1 = set([t for t in NON_ALPHA.split(s1) if t.strip()])\n",
    "    tokens2 = set([t for t in NON_ALPHA.split(s2) if t.strip()])\n",
    "    return len(tokens1 & tokens2) / max(1, len(tokens1 | tokens2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert jaccard_similarity(\"a = 1\", \"a = 2\") == 0.3333333333333333\n",
    "assert jaccard_similarity(\"a = 1\", \"a = 1\") == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BenchmarkCleaner:\n",
    "    \"\"\"\n",
    "    A class to clean the benchmark dataset.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        benchmarks: list, # The list of benchmarks to clean.\n",
    "        threshold: float = 0.5, # The threshold to use for the MinHashLSH index.\n",
    "        num_perm: int = 128 # The number of permutations to use for the MinHashLSH index.\n",
    "        ):\n",
    "        self.benchmarks = benchmarks\n",
    "        self.threshold = threshold\n",
    "        self.num_perm = num_perm\n",
    "    \n",
    "    def clean(\n",
    "        self,\n",
    "        ds: Dataset, # The dataset to clean.\n",
    "        column: str, # The column to clean.\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Clean the dataset. This function does the following:\n",
    "        1. Hash the content of the provided dataset using MinHash.\n",
    "        2. Iterate over the benchmark datasets and hash their content.\n",
    "        3. Query the MinHashLSH index for each record in the provided dataset against the benchmark datasets.\n",
    "        4. Filter out the records that have a high similarity with the benchmark datasets.\n",
    "        5. Return the cleaned dataset.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        DATA_SIZE = len(ds)\n",
    "        ds = ds.map(\n",
    "            lambda _, idx: {\"__id__\": idx},\n",
    "            with_indices=True,\n",
    "            num_proc=os.cpu_count(),\n",
    "            desc=\"Adding index...\",\n",
    "        )\n",
    "        hashed_ds = ds.map(\n",
    "            function=hash_content,\n",
    "            fn_kwargs={\"num_perm\": self.num_perm},\n",
    "            input_columns=[\"__id__\", column],\n",
    "            remove_columns=[column],\n",
    "            num_proc=os.cpu_count(),\n",
    "            desc=f\"Fingerprinting...\",\n",
    "        )\n",
    "        dup_ids = set() # The set of duplicate ids that should be filtered out.\n",
    "        # Iterate over the benchmark datasets, hash their content and query the MinHashLSH index.\n",
    "        for bm in self.benchmarks:\n",
    "            globals()[bm[\"name\"]] = MinHashLSH(\n",
    "                threshold=self.threshold,\n",
    "                num_perm=self.num_perm,\n",
    "            )\n",
    "\n",
    "            # Load the benchmark dataset and the necessary splits\n",
    "            benchmark_ds = load_dataset(bm[\"name\"], split=\"+\".join(bm[\"splits\"]))\n",
    "            # remove unused columns\n",
    "            columns_to_remove = [c for c in benchmark_ds.column_names if c not in bm[\"columns\"]]\n",
    "            benchmark_ds = benchmark_ds.remove_columns(columns_to_remove)\n",
    "            benchmark_ds = benchmark_ds.map(\n",
    "                    function=lambda x, idx: {\n",
    "                        **hash_content(\n",
    "                            idx,\n",
    "                            \" \".join(\n",
    "                                [x[col] if isinstance(x[col], str) else \" \".join(x[col]) for col in bm[\"columns\"]]\n",
    "                            ),\n",
    "                            num_perm=self.num_perm,\n",
    "                        ),\n",
    "                        \"__content__\": \" \".join(\n",
    "                            [x[col] if isinstance(x[col], str) else \" \".join(x[col]) for col in bm[\"columns\"]]\n",
    "                        ),\n",
    "                    },\n",
    "                    num_proc=4,\n",
    "                    with_indices=True,\n",
    "                    desc=f\"Fingerprinting...\",\n",
    "                )\n",
    "            \n",
    "            # Update the global variable with the MinHashLSH index.\n",
    "            with globals()[bm[\"name\"]].insertion_session() as session:\n",
    "                for record in benchmark_ds:\n",
    "                    session.insert(record[\"__id__\"], LeanMinHash(seed=MINHASH_SEED, hashvalues=record[\"__signature__\"]))\n",
    "\n",
    "            # remove unused columns\n",
    "            hashed_ds = hashed_ds.remove_columns([c for c in hashed_ds.column_names if c not in [\"__id__\", \"__signature__\"]])\n",
    "            queried = hashed_ds.map(\n",
    "                function=lambda x, y: query_content(x, y, index=globals()[bm[\"name\"]]),\n",
    "                num_proc=os.cpu_count(),\n",
    "                input_columns=[\n",
    "                    \"__id__\",\n",
    "                    \"__signature__\",\n",
    "                ],\n",
    "                remove_columns=[\"__signature__\"],\n",
    "                desc=\"Querying...\",\n",
    "                features=Features(\n",
    "                    {\n",
    "                        \"__id__\": Value(\"uint64\"),\n",
    "                        \"__neighbors__\": Sequence(Value(\"string\")),\n",
    "                    }\n",
    "                ),\n",
    "            ).filter(\n",
    "                lambda x: len(x[\"__neighbors__\"]) > 0,\n",
    "                num_proc=os.cpu_count(),\n",
    "                desc=f\"Filtering...\",\n",
    "            )\n",
    "\n",
    "            # Update the set of duplicate ids.\n",
    "            for record in tqdm(\n",
    "                queried,\n",
    "                desc=f\"Checking for false positives...\",\n",
    "            ):\n",
    "                neighbors = set(record[\"__neighbors__\"])\n",
    "                curr_text = ds[record[\"__id__\"]][column]\n",
    "                for neighbor in neighbors:\n",
    "                    reference = benchmark_ds[int(neighbor)]\n",
    "                    reference_text = reference[\"__content__\"]\n",
    "                    if jaccard_similarity(curr_text, reference_text) >= self.threshold:\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                dup_ids.add(record[\"__id__\"])\n",
    "\n",
    "        # Filter out the duplicate ids.\n",
    "        final_data = ds.filter(\n",
    "            lambda idx: idx not in dup_ids,\n",
    "            input_columns=[\"__id__\"],\n",
    "            num_proc=os.cpu_count(),\n",
    "            desc=\"Filtering duplicates...\",\n",
    "        )\n",
    "\n",
    "        FINAL_DATA_SIZE = len(final_data)\n",
    "        DUP_SIZE = DATA_SIZE - FINAL_DATA_SIZE\n",
    "\n",
    "        logger.info(f\"{'Data Number':<30}: {DATA_SIZE}\")\n",
    "        logger.info(f\"{'Duplicate Number':<30}: {DUP_SIZE}\")\n",
    "        logger.info(f\"{'Duplicate Rate':<30}: {DUP_SIZE / DATA_SIZE:.2%}\")\n",
    "        logger.info(f\"{'Total Time':<30}: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking for false positives...: 100%|██████████| 8780/8780 [00:32<00:00, 269.90it/s]\n",
      "Checking for false positives...: 100%|██████████| 8674/8674 [01:05<00:00, 131.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/06/22 13:35:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Data Number                   : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>                                <a href=\"file:///tmp/ipykernel_130600/1219644843.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1219644843.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_130600/1219644843.py#131\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/06/22 13:35:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Data Number                   : \u001b[1;36m10000\u001b[0m                                \u001b]8;id=482374;file:///tmp/ipykernel_130600/1219644843.py\u001b\\\u001b[2m1219644843.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=805758;file:///tmp/ipykernel_130600/1219644843.py#131\u001b\\\u001b[2m131\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/06/22 13:35:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Data Number                   : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>                                <a href=\"file:///tmp/ipykernel_130600/1219644843.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1219644843.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_130600/1219644843.py#131\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/06/22 13:35:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Data Number                   : \u001b[1;36m10000\u001b[0m                                \u001b]8;id=905257;file:///tmp/ipykernel_130600/1219644843.py\u001b\\\u001b[2m1219644843.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=559082;file:///tmp/ipykernel_130600/1219644843.py#131\u001b\\\u001b[2m131\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Duplicate Number              : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4612</span>                                 <a href=\"file:///tmp/ipykernel_130600/1219644843.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1219644843.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_130600/1219644843.py#132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Duplicate Number              : \u001b[1;36m4612\u001b[0m                                 \u001b]8;id=131161;file:///tmp/ipykernel_130600/1219644843.py\u001b\\\u001b[2m1219644843.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=562948;file:///tmp/ipykernel_130600/1219644843.py#132\u001b\\\u001b[2m132\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Duplicate Number              : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4612</span>                                 <a href=\"file:///tmp/ipykernel_130600/1219644843.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1219644843.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_130600/1219644843.py#132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Duplicate Number              : \u001b[1;36m4612\u001b[0m                                 \u001b]8;id=707112;file:///tmp/ipykernel_130600/1219644843.py\u001b\\\u001b[2m1219644843.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=114803;file:///tmp/ipykernel_130600/1219644843.py#132\u001b\\\u001b[2m132\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Duplicate Rate                : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46.12</span>%                               <a href=\"file:///tmp/ipykernel_130600/1219644843.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1219644843.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_130600/1219644843.py#133\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Duplicate Rate                : \u001b[1;36m46.12\u001b[0m%                               \u001b]8;id=721401;file:///tmp/ipykernel_130600/1219644843.py\u001b\\\u001b[2m1219644843.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=906674;file:///tmp/ipykernel_130600/1219644843.py#133\u001b\\\u001b[2m133\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Duplicate Rate                : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46.12</span>%                               <a href=\"file:///tmp/ipykernel_130600/1219644843.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1219644843.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_130600/1219644843.py#133\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Duplicate Rate                : \u001b[1;36m46.12\u001b[0m%                               \u001b]8;id=253796;file:///tmp/ipykernel_130600/1219644843.py\u001b\\\u001b[2m1219644843.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=265231;file:///tmp/ipykernel_130600/1219644843.py#133\u001b\\\u001b[2m133\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Total Time                    : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101.81</span> seconds                       <a href=\"file:///tmp/ipykernel_130600/1219644843.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1219644843.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_130600/1219644843.py#134\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Total Time                    : \u001b[1;36m101.81\u001b[0m seconds                       \u001b]8;id=726981;file:///tmp/ipykernel_130600/1219644843.py\u001b\\\u001b[2m1219644843.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=951963;file:///tmp/ipykernel_130600/1219644843.py#134\u001b\\\u001b[2m134\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Total Time                    : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101.81</span> seconds                       <a href=\"file:///tmp/ipykernel_130600/1219644843.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1219644843.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_130600/1219644843.py#134\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Total Time                    : \u001b[1;36m101.81\u001b[0m seconds                       \u001b]8;id=941733;file:///tmp/ipykernel_130600/1219644843.py\u001b\\\u001b[2m1219644843.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=225928;file:///tmp/ipykernel_130600/1219644843.py#134\u001b\\\u001b[2m134\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmarks = [\n",
    "    {\n",
    "        \"name\": \"openai_humaneval\",\n",
    "        \"splits\": [\"test\"],\n",
    "        \"columns\": [\"prompt\", \"canonical_solution\", \"test\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mbpp\",\n",
    "        \"splits\": [\"validation\", \"test\"],\n",
    "        \"columns\": [\"text\", \"code\", \"test_list\"],\n",
    "    },\n",
    "]\n",
    "ds = load_dataset(\"bigcode/the-stack-smol\", data_dir=\"data/python\", split=\"train\")\n",
    "bench_cleaner = BenchmarkCleaner(benchmarks, threshold=0.1, num_perm=128)\n",
    "ds = bench_cleaner.clean(ds, \"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'avg_line_length', 'max_line_length', 'alphanum_fraction', 'licenses', 'repository_name', 'path', 'size', 'lang', '__id__'],\n",
       "    num_rows: 5388\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('clean_bench')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
