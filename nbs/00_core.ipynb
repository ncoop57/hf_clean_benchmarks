{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datasets import Dataset, load_dataset, Features, Sequence, Value\n",
    "from datasketch import LeanMinHash, MinHash, MinHashLSH\n",
    "from rich.logging import RichHandler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "multiprocessing.set_start_method(\"fork\", force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(RichHandler(rich_tracebacks=True))\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "MINHASH_SEED = 42\n",
    "NON_ALPHA = re.compile(\"[^A-Za-z_0-9]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def hash_content(idx: int, content: str, *, num_perm: int):\n",
    "    \"\"\"\n",
    "    Hash the content of a record using MinHash. This function should be\n",
    "    used with multiprocessing and it scales well with the number of cores.\n",
    "    Parameters\n",
    "    ----------\n",
    "    idx : int\n",
    "        The index of the record.\n",
    "    content : str\n",
    "        The content to embed.\n",
    "    num_perm : int\n",
    "        The number of permutations to use in the MinHash object.\n",
    "    seed : int\n",
    "        The seed to use in the MinHash object.\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        The MinHash signature and the index of the record.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> result = hash_content(0, \"Hello world!\", num_perm=128)\n",
    "    >>> result[\"__id__\"]\n",
    "    0\n",
    "    >>> result[\"__signature__\"].shape\n",
    "    (128,)\n",
    "    >>> result[\"__signature__\"].dtype\n",
    "    dtype('uint64')\n",
    "    \"\"\"\n",
    "    m = MinHash(num_perm=num_perm, seed=MINHASH_SEED)\n",
    "    m.update_batch([token.encode(\"utf-8\") for token in {t for t in NON_ALPHA.split(content) if t}])\n",
    "    return {\"__signature__\": m.hashvalues, \"__id__\": idx}\n",
    "\n",
    "def query_content(idx: int, signature: np.ndarray, *, index: MinHashLSH):\n",
    "    \"\"\"\n",
    "    Query the MinHashLSH index for the record. This function can be used with multiprocessing\n",
    "    as long as the index is shared across processes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    index : MinHashLSH\n",
    "        The MinHashLSH index. It is shared across all processes when using multiprocessing with fork without copy.\n",
    "    record : Dict[str, Any]\n",
    "        The record to query.\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        The query result.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"__neighbors__\": [\n",
    "            str(dup_idx)\n",
    "            for dup_idx in index.query(\n",
    "                LeanMinHash(seed=MINHASH_SEED, hashvalues=signature),\n",
    "            )\n",
    "        ],\n",
    "        \"__id__\": idx,\n",
    "    }\n",
    "\n",
    "def jaccard_similarity(s1: str, s2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the jaccard similarity between two code snippets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    s1 : str\n",
    "        The first code snippet.\n",
    "    s2 : str\n",
    "        The second code snippet.\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The jaccard similarity between the two code snippets.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> jaccard_similarity(\"a = 1\", \"a = 2\")\n",
    "    0.3333333333333333\n",
    "    >>> jaccard_similarity(\"a = 1\", \"a = 1\")\n",
    "    1.0\n",
    "    \"\"\"\n",
    "    tokens1 = set([t for t in NON_ALPHA.split(s1) if t.strip()])\n",
    "    tokens2 = set([t for t in NON_ALPHA.split(s2) if t.strip()])\n",
    "    return len(tokens1 & tokens2) / max(1, len(tokens1 | tokens2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BenchmarkCleaner:\n",
    "    def __init__(self, benchmarks, threshold = 0.5, num_perm = 128):\n",
    "        self.benchmarks = benchmarks\n",
    "        self.threshold = threshold\n",
    "        self.num_perm = num_perm\n",
    "    \n",
    "    def clean(self, ds, column):\n",
    "        start_time = time.time()\n",
    "        DATA_SIZE = len(ds)\n",
    "        ds = ds.map(\n",
    "            lambda _, idx: {\"__id__\": idx},\n",
    "            with_indices=True,\n",
    "            num_proc=os.cpu_count(),\n",
    "            desc=\"Adding index...\",\n",
    "        )\n",
    "        hashed_ds = ds.map(\n",
    "            function=hash_content,\n",
    "            fn_kwargs={\"num_perm\": self.num_perm},\n",
    "            input_columns=[\"__id__\", column],\n",
    "            remove_columns=[column],\n",
    "            num_proc=os.cpu_count(),\n",
    "            desc=f\"Fingerprinting...\",\n",
    "        )\n",
    "        dup_ids = set()\n",
    "        for bm in self.benchmarks:\n",
    "            globals()[bm[\"name\"]] = MinHashLSH(\n",
    "                threshold=self.threshold,\n",
    "                num_perm=self.num_perm,\n",
    "            )\n",
    "            benchmark_ds = load_dataset(bm[\"name\"], split=\"+\".join(bm[\"splits\"]))\n",
    "            columns_to_remove = [c for c in benchmark_ds.column_names if c not in bm[\"columns\"]]\n",
    "            benchmark_ds = benchmark_ds.remove_columns(columns_to_remove)\n",
    "            benchmark_ds = benchmark_ds.map(\n",
    "                    function=lambda x, idx: {\n",
    "                        **hash_content(\n",
    "                            idx,\n",
    "                            \" \".join(\n",
    "                                [x[col] if isinstance(x[col], str) else \" \".join(x[col]) for col in bm[\"columns\"]]\n",
    "                            ),\n",
    "                            num_perm=self.num_perm,\n",
    "                        ),\n",
    "                        \"__content__\": \" \".join(\n",
    "                            [x[col] if isinstance(x[col], str) else \" \".join(x[col]) for col in bm[\"columns\"]]\n",
    "                        ),\n",
    "                    },\n",
    "                    num_proc=4,\n",
    "                    with_indices=True,\n",
    "                    desc=f\"Fingerprinting...\",\n",
    "                )\n",
    "            with globals()[bm[\"name\"]].insertion_session() as session:\n",
    "                for record in benchmark_ds:\n",
    "                    session.insert(record[\"__id__\"], LeanMinHash(seed=MINHASH_SEED, hashvalues=record[\"__signature__\"]))\n",
    "\n",
    "            # remove unused columns\n",
    "            hashed_ds = hashed_ds.remove_columns([c for c in hashed_ds.column_names if c not in [\"__id__\", \"__signature__\"]])\n",
    "            queried = hashed_ds.map(\n",
    "                function=lambda x, y: query_content(x, y, index=globals()[bm[\"name\"]]),\n",
    "                num_proc=os.cpu_count(),\n",
    "                input_columns=[\n",
    "                    \"__id__\",\n",
    "                    \"__signature__\",\n",
    "                ],\n",
    "                remove_columns=[\"__signature__\"],\n",
    "                desc=\"Querying...\",\n",
    "                features=Features(\n",
    "                    {\n",
    "                        \"__id__\": Value(\"uint64\"),\n",
    "                        \"__neighbors__\": Sequence(Value(\"string\")),\n",
    "                    }\n",
    "                ),\n",
    "            ).filter(\n",
    "                lambda x: len(x[\"__neighbors__\"]) > 0,\n",
    "                num_proc=os.cpu_count(),\n",
    "                desc=f\"Filtering...\",\n",
    "            )\n",
    "\n",
    "            for record in tqdm(\n",
    "                queried,\n",
    "                desc=f\"Checking for false positives...\",\n",
    "            ):\n",
    "                neighbors = set(record[\"__neighbors__\"])\n",
    "                curr_text = ds[record[\"__id__\"]][column]\n",
    "                for neighbor in neighbors:\n",
    "                    reference = benchmark_ds[int(neighbor)]\n",
    "                    reference_text = reference[\"__content__\"]\n",
    "                    if jaccard_similarity(curr_text, reference_text) >= self.threshold:\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                dup_ids.add(record[\"__id__\"])\n",
    "\n",
    "            duplicates = ds.filter(lambda x: x[\"__id__\"] in dup_ids, num_proc=os.cpu_count())\n",
    "            final_data = ds.filter(\n",
    "                lambda idx: idx not in dup_ids,\n",
    "                input_columns=[\"__id__\"],\n",
    "                num_proc=os.cpu_count(),\n",
    "                desc=\"Filtering duplicates...\",\n",
    "            )\n",
    "\n",
    "            FINAL_DATA_SIZE = len(final_data)\n",
    "            DUP_SIZE = DATA_SIZE - FINAL_DATA_SIZE\n",
    "\n",
    "            logger.info(f\"{'Data Number':<30}: {DATA_SIZE}\")\n",
    "            logger.info(f\"{'Duplicate Number':<30}: {DUP_SIZE}\")\n",
    "            logger.info(f\"{'Duplicate Rate':<30}: {DUP_SIZE / DATA_SIZE:.2%}\")\n",
    "            logger.info(f\"{'Total Time':<30}: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "            return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration bigcode--the-stack-smol-7b51f8bde3058781\n",
      "Found cached dataset json (/home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-5cec16f7c8c87bb2.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-63fe0b2405153769.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-ae0db36e3a8aac70.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-47e23865885b5a26.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-b7beb7816a41a2f0.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-20b69e62445ba6d2.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-04b550cc438b7896.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-734bed5d2ea547a4.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-8152fba9252715fc.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-b1d43562e11c6bf1.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-e5d629b56c11e0cc.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-35a64fa7727258dd.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-487889deb6902247.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-94ff5b705df27ef9.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-9c481cefbfcfb71e.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-8d9738c4ad16c911.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-23d43d9b92f09ae4.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-70fbcad3c19eed37.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-5fe2eaed1dafe028.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-22a08ddf33afccb6.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-3053164289fa9011.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-2eb113b34088c35f.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-4866fd096748e1b6.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-28cef5d6a9b19bde.arrow\n",
      "Found cached dataset openai_humaneval (/home/nathan/.cache/huggingface/datasets/openai_humaneval/openai_humaneval/1.0.0/2955cebd73602e828fa8c0a424c594e5fab4ec863b316ca98f3d8fdb6a626e75)\n",
      "Fingerprinting... #0:   0%|          | 0/41 [00:00<?, ?ex/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Fingerprinting... #0: 100%|██████████| 41/41 [00:00<00:00, 1106.73ex/s]\n",
      "Fingerprinting... #1: 100%|██████████| 41/41 [00:00<00:00, 1155.35ex/s]\n",
      "Fingerprinting... #3: 100%|██████████| 41/41 [00:00<00:00, 1047.53ex/s]\n",
      "Fingerprinting... #2: 100%|██████████| 41/41 [00:00<00:00, 1160.67ex/s]\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-1b7e2c86ef292dac.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-20948f604ea1f0ad.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-379dd1edd17662dd.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-5e592a10425f2969.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-03158fec732246f5.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-da5f16e691be2a81.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-0ec7b11a41fb2823.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-ee7a25823d8c53fc.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-7cf441e6a6dd4696.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-a87e958dd2533af2.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-c6fb2fc1bdfb45b9.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-3c52dc3941cff191.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00000_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00001_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00002_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00003_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00004_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00005_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00006_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00007_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00008_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00009_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00010_of_00012.arrow\n",
      "Loading cached processed dataset at /home/nathan/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-7b51f8bde3058781/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-289e3462f20aa59f_00011_of_00012.arrow\n",
      "Checking for false positives...: 100%|██████████| 32/32 [00:00<00:00, 3118.30it/s]\n",
      "#0:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "#0:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "#2:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "#1:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "#3:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#4:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#5:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#6:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#7:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "#8:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#9:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#10:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "#11:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Filtering duplicates... #0:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "Filtering duplicates... #1:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "Filtering duplicates... #2:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "Filtering duplicates... #3:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Filtering duplicates... #4:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Filtering duplicates... #5:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Filtering duplicates... #6:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Filtering duplicates... #7:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Filtering duplicates... #8:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Filtering duplicates... #9:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Filtering duplicates... #10:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Filtering duplicates... #11:   0%|          | 0/1 [00:00<?, ?ba/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/06/22 07:47:41] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Data Number                   : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>                                <a href=\"file:///tmp/ipykernel_107938/2136538966.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2136538966.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_107938/2136538966.py#104\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/06/22 07:47:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Data Number                   : \u001b[1;36m10000\u001b[0m                                \u001b]8;id=253313;file:///tmp/ipykernel_107938/2136538966.py\u001b\\\u001b[2m2136538966.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=829698;file:///tmp/ipykernel_107938/2136538966.py#104\u001b\\\u001b[2m104\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Duplicate Number              : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>                                   <a href=\"file:///tmp/ipykernel_107938/2136538966.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2136538966.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_107938/2136538966.py#105\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Duplicate Number              : \u001b[1;36m28\u001b[0m                                   \u001b]8;id=469304;file:///tmp/ipykernel_107938/2136538966.py\u001b\\\u001b[2m2136538966.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=80035;file:///tmp/ipykernel_107938/2136538966.py#105\u001b\\\u001b[2m105\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Duplicate Rate                : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.28</span>%                                <a href=\"file:///tmp/ipykernel_107938/2136538966.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2136538966.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_107938/2136538966.py#106\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Duplicate Rate                : \u001b[1;36m0.28\u001b[0m%                                \u001b]8;id=794507;file:///tmp/ipykernel_107938/2136538966.py\u001b\\\u001b[2m2136538966.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=583539;file:///tmp/ipykernel_107938/2136538966.py#106\u001b\\\u001b[2m106\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Total Time                    : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.65</span> seconds                         <a href=\"file:///tmp/ipykernel_107938/2136538966.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2136538966.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_107938/2136538966.py#107\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Total Time                    : \u001b[1;36m2.65\u001b[0m seconds                         \u001b]8;id=783507;file:///tmp/ipykernel_107938/2136538966.py\u001b\\\u001b[2m2136538966.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=973624;file:///tmp/ipykernel_107938/2136538966.py#107\u001b\\\u001b[2m107\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASETS_TO_CHECK = [\n",
    "    {\n",
    "        \"name\": \"openai_humaneval\",\n",
    "        \"splits\": [\"test\"],\n",
    "        \"columns\": [\"prompt\", \"canonical_solution\", \"test\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mbpp\",\n",
    "        \"splits\": [\"validation\", \"test\"],\n",
    "        \"columns\": [\"text\", \"code\", \"test_list\"],\n",
    "    },\n",
    "]\n",
    "ds = load_dataset(\"bigcode/the-stack-smol\", data_dir=\"data/python\", split=\"train\")\n",
    "bench_cleaner = BenchmarkCleaner(DATASETS_TO_CHECK, threshold=0.1, num_perm=128)\n",
    "ds = bench_cleaner.clean(ds, \"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'avg_line_length', 'max_line_length', 'alphanum_fraction', 'licenses', 'repository_name', 'path', 'size', 'lang', '__id__'],\n",
       "    num_rows: 9972\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('clean_bench')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
