[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "hf_clean_benchmarks",
    "section": "",
    "text": "This repository is heavily inspired by the BigCode repository and is mostly a refactoring of their code. Specifically, the main person who worked on this repository is Chenghao Mou (Awesome work!)."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "hf_clean_benchmarks",
    "section": "Install",
    "text": "Install\npip install hf_clean_benchmarks"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "hf_clean_benchmarks",
    "section": "How to use",
    "text": "How to use\n\nUsing the API\nFirst you need to specify which benchmarks you want to clean your data of. You can do this by creating dictionary with the benchmark name in huggingface’s datasets repository as the key and the name of the column containing the benchmark data as the value. For example, if you want to clean your data of the HumanEval and LAMBADA benchmarks, you would do the following:\n\n# Benchmarks to clean\nbenchmarks = [\n    {\n        \"name\": \"openai_humaneval\",\n        \"splits\": [\"test\"],\n        \"columns\": [\"prompt\", \"canonical_solution\", \"test\"],\n    },\n    {\n        \"name\": \"lambada\",\n        \"splits\": [\"test\"],\n        \"columns\": [\"text\"],\n    },\n]\n\nYou then pass this dictionary to the BenchmarkCleaner class. This class will download the benchmarks and construct the suffix array for each benchmark. You can then use the clean method to clean a huggingface dataset. For example:\n\nfrom datasets import load_dataset\nfrom hf_clean_benchmarks.core import BenchmarkCleaner\n\ncleaner = BenchmarkCleaner(benchmarks, threshold=0.1, num_perm=128)\n\n# load your dataset\ndataset = load_dataset(\"bigcode/the-stack-smol\", data_dir=\"data/python\", split=\"train\")\n\n# clean the dataset\ncleaned_dataset = cleaner.clean(dataset, column=\"content\")\n\nChecking for false positives...: 100%|██████████| 8780/8780 [00:34<00:00, 251.05it/s]\nChecking for false positives...: 100%|██████████| 8805/8805 [07:34<00:00, 19.39it/s]\n\n\n[11/06/22 10:34:43] INFO     Data Number                   : 10000                                      core.py:210\n\n\n\n                    INFO     Duplicate Number              : 4033                                       core.py:211\n\n\n\n                    INFO     Duplicate Rate                : 40.33%                                     core.py:212\n\n\n\n                    INFO     Total Time                    : 493.73 seconds                             core.py:213\n\n\n\n\ncleaned_dataset\n\nDataset({\n    features: ['content', 'avg_line_length', 'max_line_length', 'alphanum_fraction', 'licenses', 'repository_name', 'path', 'size', 'lang', '__id__'],\n    num_rows: 5967\n})\n\n\n\n\nUsing the CLI\nFirst you need to specify which benchmarks you want to clean your data of. You can do this by creating a json file with the benchmark name in huggingface’s datasets repository as the key and the name of the column containing the benchmark data as the value. For example, if you want to clean your data of the HumanEval and LAMBADA benchmarks, you would do the following:\nfile: benchmarks.json\n[\n    {\n        \"name\": \"openai_humaneval\",\n        \"splits\": [\"test\"],\n        \"columns\": [\"prompt\", \"canonical_solution\", \"test\"],\n    },\n    {\n        \"name\": \"lambada\",\n        \"splits\": [\"test\"],\n        \"columns\": [\"text\"],\n    },\n]\nYou then pass this json file to the clean_dataset command. This command will download the benchmarks and construct the suffix array for each benchmark. You can then use the clean command to clean a huggingface dataset. For example:\nclean_dataset \\\n    --dataset_name bigcode/the-stack-smol \\\n    --column_name content \\\n    --benchmark_configs_path benchmarks.json \\\n    --output_path /tmp/test.jsonl \\\n    --data_dir data/python \\\n    --dataset_split train \\\n    --save_json"
  },
  {
    "objectID": "cli.html",
    "href": "cli.html",
    "title": "cli",
    "section": "",
    "text": "source\n\nclean_dataset\n\n clean_dataset (dataset_name:str, column_name:str,\n                benchmark_configs_path:str, output_path:str,\n                dataset_config_name:str=None, data_dir:str=None,\n                dataset_split:str='train', save_json:bool=False)\n\nClean a dataset using a benchmark configuration file.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_name\nstr\n\nName of the dataset to clean\n\n\ncolumn_name\nstr\n\nName of the column to clean\n\n\nbenchmark_configs_path\nstr\n\nPath to the benchmark configuration file\n\n\noutput_path\nstr\n\nPath to where the cleaned dataset will be saved\n\n\ndataset_config_name\nstr\nNone\nName of the dataset configuration to use\n\n\ndata_dir\nstr\nNone\nPath to the data files to use\n\n\ndataset_split\nstr\ntrain\nName of the dataset split to clean\n\n\nsave_json\nbool\nFalse\nWhether to save the cleaned dataset as a JSON file\n\n\n\n\nclean_dataset(\n    dataset_name=\"bigcode/the-stack-smol\",\n    column_name=\"content\",\n    benchmark_configs_path=temp.name,\n    output_path=\"/tmp/test.jsonl\",\n    data_dir=\"data/python\",\n    dataset_split=\"train\",\n    save_json=True,\n)\n\nChecking for false positives...: 100%|██████████| 8780/8780 [00:33<00:00, 260.81it/s]\nChecking for false positives...: 100%|██████████| 8674/8674 [01:07<00:00, 129.20it/s]\n\n\n[11/06/22 10:39:25] INFO     Data Number                   : 10000                                      core.py:210\n\n\n\n                    INFO     Duplicate Number              : 4612                                       core.py:211\n\n\n\n                    INFO     Duplicate Rate                : 46.12%                                     core.py:212\n\n\n\n                    INFO     Total Time                    : 104.49 seconds                             core.py:213\n\n\n\nCreating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.77ba/s]"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nhash_content\n\n hash_content (idx:int, content:str, num_perm:int)\n\nHash the content of a record using MinHash. This function should be used with multiprocessing and it scales well with the number of cores.\n\n\n\n\nType\nDetails\n\n\n\n\nidx\nint\nindex of the document\n\n\ncontent\nstr\ncontent of the document\n\n\nnum_perm\nint\n\n\n\n\n\nresult = hash_content(0, \"Hello world!\", num_perm=128)\nassert result[\"__id__\"] == 0\nassert result[\"__signature__\"].shape == (128,)\nassert result[\"__signature__\"].dtype == np.dtype('uint64')\n\n\nsource\n\n\nquery_content\n\n query_content (idx:int, signature:numpy.ndarray,\n                index:datasketch.lsh.MinHashLSH)\n\nQuery the MinHashLSH index for the record. This function can be used with multiprocessing as long as the index is shared across processes. Parameters.\n\n\n\n\nType\nDetails\n\n\n\n\nidx\nint\nindex of the document\n\n\nsignature\nndarray\nMinHash signature of the document\n\n\nindex\nMinHashLSH\n\n\n\n\n\nsource\n\n\njaccard_similarity\n\n jaccard_similarity (s1:str, s2:str)\n\nCalculate the jaccard similarity between two code snippets.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ns1\nstr\nThe first string to compare.\n\n\ns2\nstr\nThe second string to compare.\n\n\nReturns\nfloat\nThe Jaccard similarity between the two strings.\n\n\n\n\nassert jaccard_similarity(\"a = 1\", \"a = 2\") == 0.3333333333333333\nassert jaccard_similarity(\"a = 1\", \"a = 1\") == 1.0\n\n\nsource\n\n\nconvert_list_to_dict\n\n convert_list_to_dict (list)\n\n\nsource\n\n\nconfig_lists\n\n config_lists (name)\n\n\nos.environ[\"HF_ACCESS_TOKEN\"] = \"<TOKEN>\"\nds_dict = config_lists(\"amazon_reviews_multi\")\nds_dict\n\n{'all_languages': ['validation', 'test']}\n\n\n\nsource\n\n\nprocess_ds_config\n\n process_ds_config (name, ds_dict)\n\n\nds = next(process_ds_config(\"amazon_reviews_multi\", ds_dict))\nds.features\n\n\nsource\n\n\nBenchmarkCleaner\n\n BenchmarkCleaner (benchmark_names:list, threshold:float=0.5,\n                   num_perm:int=128)\n\nA class to clean the benchmark dataset.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbenchmark_names\nlist\n\nThe list of benchmark names to clean.\n\n\nthreshold\nfloat\n0.5\nThe threshold to use for the MinHashLSH index.\n\n\nnum_perm\nint\n128\nThe number of permutations to use for the MinHashLSH index.\n\n\n\n\nbenchmark_names = [\"openai_humaneval\", \"mbpp\"]\nds = load_dataset(\"bigcode/the-stack-smol\", data_dir=\"data/python\", split=\"train\")\nbench_cleaner = BenchmarkCleaner(benchmark_names, threshold=0.1, num_perm=128)\nds = bench_cleaner.clean(ds, \"content\")\n\n                                                                        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                             \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n    \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n   \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                   \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n       \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n                                             \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                   \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n       \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n                                           \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n   \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                   \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n       \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                    \n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n       \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n                                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n     \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n   \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n                                   \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n   \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                            \n\n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n      \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n   \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                   \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\n\n\n\n   \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                             \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n     \n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                   \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                \n\n\n[01/12/23 05:06:31] INFO     Data Number                   : 10000                                3890709806.py:127\n\n\n\n                    INFO     Duplicate Number              : 4611                                 3890709806.py:128\n\n\n\n                    INFO     Duplicate Rate                : 46.11%                               3890709806.py:129\n\n\n\n                    INFO     Total Time                    : 151.11 seconds                       3890709806.py:130"
  }
]